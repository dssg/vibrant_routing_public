{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc4d5b1e",
   "metadata": {},
   "source": [
    "# Postmodel Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1c98e7",
   "metadata": {},
   "source": [
    "## Import relevant packages and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57758b19-80a5-466d-9ed3-b103fb4ec948",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd62111",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from config.project_constants import MODELING_CONFIG_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a3ecea-fa50-417e-b303-ba599b400c55",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b79bd07-02a9-4861-8bfe-c6e1ff6ff6e4",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_color_codes(\"muted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ea9b5a-917b-4b12-baa2-2a96394a88c6",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "\n",
    "alt.renderers.enable(\"default\")\n",
    "\n",
    "from src.utils.plot_util import (\n",
    "    plot_scores_vs_actual_labels,\n",
    "    compare_best_of_models,\n",
    "    compare_inside_model_class,\n",
    ")\n",
    "from src.utils.sql_util import (\n",
    "    get_db_conn,\n",
    "    get_predictions_from_db,\n",
    "    get_topk_models,\n",
    "    get_best_model_from_model_class,\n",
    "    get_metrics_from_db,\n",
    "    get_saved_model_info_from_db,\n",
    "    get_predictions_with_census_data,\n",
    "    get_best_model_per_model_class,\n",
    "    #get_feature_importance_from_db,\n",
    "    get_predictions_with_feature_data,\n",
    "    get_calibration_model,\n",
    "    get_predictions_with_source_data,\n",
    ")\n",
    "from src.utils.pipeline_util import feature_importance\n",
    "from src.utils.util import get_feature_groups_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4e6349",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open(\"../\" + MODELING_CONFIG_FILE) as f:\n",
    "    modeling_config = yaml.load(f, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e62793-7b49-49af-b3ea-0437e4f60b71",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "db_conn = get_db_conn()\n",
    "\n",
    "get_topk_models_wrapper = lambda db_conn, k=1: get_topk_models(db_conn=db_conn, k=k)\n",
    "get_best_from_model_class_wrapper = (\n",
    "    lambda db_conn, model_class, metric_of_interest: get_best_model_from_model_class(\n",
    "        db_conn=db_conn, model_class=model_class, metric_of_interest=metric_of_interest\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddaf7ce8-1a8a-4f67-8ec9-5370895a34e6",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def threshold_scores(data, threshold=0.5):\n",
    "    result_dict = {\n",
    "        \"y_true\": data[\"y_true\"].astype(int).values,\n",
    "        \"y_pred\": (data[\"y_predicted\"] >= threshold).astype(int).values,\n",
    "    }\n",
    "    return pd.DataFrame(result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3861a4c6",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "import os\n",
    "\n",
    "plots_folder_path = modeling_config[\"plots_folder_path\"]\n",
    "plots_folder_path_today = modeling_config[\"plots_folder_path\"] + str(date.today())\n",
    "\n",
    "# If plots_folder_path_today doesn't exist:\n",
    "if not os.path.exists(plots_folder_path_today):\n",
    "    os.makedirs(plots_folder_path_today)\n",
    "    print(f\"The new directory is created: {plots_folder_path_today}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8873448b",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "plots_folder_path_today += \"/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f0b6d9-dd86-41e1-ac6b-fcc64d8447a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Analyse performance of the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b2e25d",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "model_classes = [\n",
    "    \"AnswerRateAtCenter\",\n",
    "    \"AdaBoostClassifier\",\n",
    "    \"ExtraTreesClassifier\",\n",
    "    \"ScaledLogisticRegression\",\n",
    "    \"DecisionTreeClassifier\",\n",
    "    \"RandomForestClassifier\",\n",
    "    \"LogisticRegression\",\n",
    "]\n",
    "\n",
    "results = get_best_model_per_model_class(\n",
    "    db_conn=db_conn, model_class=model_classes, metric_of_interest=\"auc-roc\"\n",
    ")\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0046a899-6f2e-4791-a2c3-2baee7cdafd9",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "top_model = get_topk_models_wrapper(db_conn, 1)\n",
    "best_model_id = top_model.model_id[0]\n",
    "best_model_name = top_model.model_class[0]\n",
    "best_experiment_id = top_model.experiment_id[0]\n",
    "display(top_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb5fc5e-f4be-4c6d-a4f3-e5e330110e56",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "print(\"These are the parameters that characterize the model:\")\n",
    "get_saved_model_info_from_db(\n",
    "    db_conn=db_conn, model_id=best_model_id, info_to_get=\"parameters\"\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae988a3-2818-42a4-97f8-55d5881ffd74",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "best_model_results = get_predictions_from_db(\n",
    "    db_conn=db_conn, experiment_id=best_experiment_id, model_id=best_model_id\n",
    ")\n",
    "sorted_best_model_results = best_model_results.sort_values(\n",
    "    by=[\"y_true\", \"y_predicted\"],\n",
    "    inplace=False,\n",
    "    ascending=[False, False],\n",
    "    na_position=\"last\",\n",
    ")\n",
    "best_model_thresholded_results = threshold_scores(sorted_best_model_results)\n",
    "\n",
    "print(\"The confusion matrix of the best model is:\")\n",
    "metrics.confusion_matrix(**best_model_thresholded_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84e47c9",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"The base rate of the data is {best_model_results['y_true'].sum() / len(best_model_results['y_true'])}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1328ea5-0740-460d-84e7-7fe92682e071",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Accuracy of the best model: {metrics.accuracy_score(**best_model_thresholded_results)}.\"\n",
    ")\n",
    "print(f\"F1 of the best model: {metrics.f1_score(**best_model_thresholded_results)}.\")\n",
    "print(f\"Worst AUC-ROC of the best model: {top_model['worst_value'][0]}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e689dd",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "best_model_fpr, best_model_tpr, thresholds = metrics.roc_curve(\n",
    "    best_model_results[\"y_true\"], best_model_results[\"y_predicted\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6401cf-e8ff-4fda-808f-fc3e57678e03",
   "metadata": {},
   "source": [
    "## Analyse best baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe482fa8-5ebd-4871-839e-5f4bfc5a608b",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "best_baseline = get_best_from_model_class_wrapper(\n",
    "    db_conn,\n",
    "    model_class=[\"AnswerRateAtCenter\", \"FeatureRanker\"],\n",
    "    metric_of_interest=\"auc-roc\",\n",
    ")\n",
    "baseline_model_id = best_baseline.model_id[0]\n",
    "baseline_experiment_id = best_baseline.experiment_id[0]\n",
    "best_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa75c928-cbbc-42f9-8d7e-a79be09c77c9",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "print(\"These are the parameters that characterize the model:\")\n",
    "get_saved_model_info_from_db(\n",
    "    db_conn=db_conn, model_id=best_model_id, info_to_get=\"parameters\"\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e1d478-a07a-4a08-8b6d-cbe0486b82ad",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "baseline_model_results = get_predictions_from_db(\n",
    "    db_conn=db_conn, model_id=baseline_model_id, experiment_id=baseline_experiment_id\n",
    ")\n",
    "sorted_baseline_model_results = baseline_model_results.sort_values(\n",
    "    by=[\"y_true\", \"y_predicted\"],\n",
    "    inplace=False,\n",
    "    ascending=[False, False],\n",
    "    na_position=\"last\",\n",
    ")\n",
    "baseline_model_thresholded_results = threshold_scores(sorted_baseline_model_results)\n",
    "\n",
    "print(\"The confusion matrix of the best baseline is:\")\n",
    "metrics.confusion_matrix(**baseline_model_thresholded_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a474b2ff",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Accuracy of the best model: {metrics.accuracy_score(**baseline_model_thresholded_results)}.\"\n",
    ")\n",
    "print(\n",
    "    f\"F1 of the best model: {metrics.f1_score(**baseline_model_thresholded_results)}.\"\n",
    ")\n",
    "print(f\"Best AUC-ROC of the best model: {best_baseline['worst_value'][0]}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59985fd9",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "baseline_model_fpr, baseline_model_tpr, thresholds = metrics.roc_curve(\n",
    "    baseline_model_results[\"y_true\"], baseline_model_results[\"y_predicted\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee6316d",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "sns.lineplot(\n",
    "    x=baseline_model_fpr,\n",
    "    y=baseline_model_tpr,\n",
    "    label=f\"Feature ranker baseline, AUC={best_baseline['worst_value'][0]:.2f}\",\n",
    "    ax=ax,\n",
    "    color=\"C0\",\n",
    ")\n",
    "plt.title(\"AUC-ROC curve\", fontsize=14)\n",
    "plt.xlabel(\"FPR\", fontsize=14)\n",
    "plt.ylabel(\"TPR\", fontsize=14)\n",
    "plt.xlim(0.0, 1.01)\n",
    "plt.ylim(0.0, 1.01)\n",
    "\n",
    "fig.savefig(f\"{plots_folder_path_today}auc_roc_best_baseline.png\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "367ea6d3",
   "metadata": {},
   "source": [
    "baseline_model_results = get_predictions_from_db(\n",
    "    db_conn=db_conn, model_id=2143, experiment_id=2143\n",
    ")\n",
    "baseline_model_fpr, baseline_model_tpr, thresholds = metrics.roc_curve(\n",
    "    baseline_model_results[\"y_true\"], baseline_model_results[\"y_predicted\"]\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "sns.lineplot(\n",
    "    x=baseline_model_fpr,\n",
    "    y=baseline_model_tpr,\n",
    "    label=f\"\"\"Answer rate baseline, AUC={\n",
    "                                metrics.roc_auc_score(\n",
    "                                    y_true=baseline_model_results[\"y_true\"], \n",
    "                                    y_score=baseline_model_results[\"y_predicted\"]\n",
    "                                ):.2f}\"\"\",\n",
    "    ax=ax,\n",
    "    color=\"C0\",\n",
    ")\n",
    "plt.title(\"AUC-ROC curve\", fontsize=14)\n",
    "plt.xlabel(\"FPR\", fontsize=14)\n",
    "plt.ylabel(\"TPR\", fontsize=14)\n",
    "plt.xlim(0.0, 1.01)\n",
    "plt.ylim(0.0, 1.01)\n",
    "\n",
    "fig.savefig(f\"{plots_folder_path_today}auc_roc_best_baseline.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5200df",
   "metadata": {},
   "source": [
    "## Compare best model with best baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5c299c-1237-498b-ac68-004c5aba1743",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "sns.lineplot(\n",
    "    x=best_model_fpr,\n",
    "    y=best_model_tpr,\n",
    "    label=f\"{best_model_name}, AUC={top_model['worst_value'][0]:.2f}\",\n",
    "    ax=ax,\n",
    "    color=\"C1\",\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=baseline_model_fpr,\n",
    "    y=baseline_model_tpr,\n",
    "    label=f\"Baseline, AUC={best_baseline['worst_value'][0]:.2f}\",\n",
    "    ax=ax,\n",
    "    color=\"C0\",\n",
    ")\n",
    "plt.title(\"AUC-ROC curve\", fontsize=14)\n",
    "plt.xlabel(\"FPR\", fontsize=14)\n",
    "plt.ylabel(\"TPR\", fontsize=14)\n",
    "plt.xlim(0.0, 1.01)\n",
    "plt.ylim(0.0, 1.01)\n",
    "\n",
    "fig.savefig(f\"{plots_folder_path_today}auc_roc_best_model_vs_best_baseline.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcf31e5-7a37-4eae-bdc3-c22eaacbde77",
   "metadata": {},
   "source": [
    "### Precision and Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f01f68",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "list_to_plot = {\n",
    "    \"Best model\": sorted_best_model_results,\n",
    "    \"Best baseline\": sorted_baseline_model_results,\n",
    "}\n",
    "fig, ax = plt.subplots(2, 2, figsize=(32, 10))\n",
    "plt.subplots_adjust(left=0.1, bottom=0.2, right=0.4, top=0.8, wspace=0.4, hspace=0.4)\n",
    "\n",
    "index = 0\n",
    "for item, model_results in list_to_plot.items():\n",
    "    (\n",
    "        best_model_precision,\n",
    "        best_model_recall,\n",
    "        best_model_threshold,\n",
    "    ) = metrics.precision_recall_curve(\n",
    "        model_results[\"y_true\"], model_results[\"y_predicted\"]\n",
    "    )\n",
    "\n",
    "    # Precision-recall curve for best model\n",
    "    sns.lineplot(\n",
    "        x=best_model_threshold, y=best_model_precision[:-1], ax=ax[index][0], color=\"C0\"\n",
    "    )\n",
    "    ax[index][0].set_xlabel(\"Threshold\", fontsize=14)\n",
    "    ax[index][0].set_ylabel(\"Precision\", fontsize=14, color=\"C0\")\n",
    "    ax[index][0].set_ylim(0, 1)\n",
    "\n",
    "    ax2 = ax[index][0].twinx()\n",
    "    sns.lineplot(x=best_model_threshold, y=best_model_recall[:-1], ax=ax2, color=\"C1\")\n",
    "    ax2.set_ylabel(\"Recall\", fontsize=14, color=\"C1\", rotation=-90, labelpad=20)\n",
    "\n",
    "    ax[index][0].set_title(item + \" - Precision-Recall curve\", fontsize=16)\n",
    "\n",
    "    # Precision-recall curve for best model\n",
    "    sns.lineplot(\n",
    "        x=best_model_recall[:-1],\n",
    "        y=best_model_precision[:-1],\n",
    "        ax=ax[index][1],\n",
    "        color=\"C0\",\n",
    "    )\n",
    "    ax[index][1].set_xlabel(\"Recall\", fontsize=14)\n",
    "    ax[index][1].set_ylabel(\"Precision\", fontsize=14)\n",
    "    ax[index][1].set_title(item + \" - Precision-Recall (best) curve\", fontsize=16)\n",
    "    ax[index][1].set_ylim(0, 1)\n",
    "\n",
    "    index += 1\n",
    "\n",
    "fig.savefig(\n",
    "    f\"{plots_folder_path_today}precision_recall_best_model_vs_best_baseline.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28169a52-d73c-4a8c-baac-f80dc12fc393",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a90e6c9",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "\n",
    "pio.renderers.default = \"notebook\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9a15e7-9c97-4f56-ba2c-853d27be0c50",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "plot_scores_vs_actual_labels(\n",
    "    best_model_results[\"y_true\"],\n",
    "    best_model_results[\"y_predicted\"],\n",
    "    show_plot=True,\n",
    "    save_plot=True,\n",
    "    title=\"Best model: distribution of the scores vs. the actual labels\",\n",
    "    plot_prefix_filename=f\"{plots_folder_path_today}best_model_{best_model_id}_\",\n",
    ")\n",
    "\n",
    "plot_scores_vs_actual_labels(\n",
    "    baseline_model_results[\"y_true\"],\n",
    "    baseline_model_results[\"y_predicted\"],\n",
    "    show_plot=True,\n",
    "    save_plot=True,\n",
    "    title=\"Best baseline: distribution of the scores vs. the actual labels\",\n",
    "    plot_prefix_filename=f\"{plots_folder_path_today}best_baseline_{baseline_model_id}_\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb3d10c",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "compare_best_of_models(\n",
    "    db_conn=db_conn,\n",
    "    plot_folder_name=plots_folder_path_today,\n",
    "    save_plot=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4bdbe6c8",
   "metadata": {},
   "source": [
    "compare_best_of_models(\n",
    "    db_conn=db_conn,\n",
    "    plot_folder_name=plots_folder_path_today,\n",
    "    save_plot=True,\n",
    "    only_show_best_models=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86465230",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "compare_inside_model_class(\n",
    "    db_conn=db_conn,\n",
    "    model_class=\"ScaledLogisticRegression\",\n",
    "    plot_folder_name=plots_folder_path_today,\n",
    "    save_plot=True,\n",
    "    show_plot=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480f383f",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "compare_inside_model_class(\n",
    "    db_conn=db_conn,\n",
    "    model_class=\"RandomForestClassifier\",\n",
    "    plot_folder_name=plots_folder_path_today,\n",
    "    save_plot=True,\n",
    "    show_plot=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3492ff22",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "compare_inside_model_class(\n",
    "    db_conn=db_conn,\n",
    "    model_class=\"DecisionTreeClassifier\",\n",
    "    plot_folder_name=plots_folder_path_today,\n",
    "    save_plot=True,\n",
    "    show_plot=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4ae7bf",
   "metadata": {},
   "source": [
    "# Bias audit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb2c561",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from aequitas.group import Group\n",
    "from aequitas.bias import Bias\n",
    "from aequitas.fairness import Fairness\n",
    "import aequitas.plot as ap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38692f3",
   "metadata": {},
   "source": [
    "To get the complete list of available `variables_of_interest` you should first load the DataFrame `preds_and_census_data` and then run the following line of code:\n",
    "> print(*preds_and_census_data.columns, sep=\"', '\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525ffc6e",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "variables_of_interest = [\n",
    "    \"population_size\",\n",
    "    \"median_hh_income\",\n",
    "    \"gini_index\",\n",
    "    \"health_insurance_no_perc\",\n",
    "    \"race_white_perc\",\n",
    "    \"race_black_or_african_american_perc\",\n",
    "    \"race_american_indian_and_alaska_native_perc\",\n",
    "    \"race_asian_perc\",\n",
    "    \"race_native_hawaiian_and_other_pacific_islander_perc\",\n",
    "    \"race_hisp_latino_perc\",\n",
    "    \"race_some_other_perc\",\n",
    "    \"race_two_races_or_more_perc\",\n",
    "    \"born_us_perc\",\n",
    "    \"total_male_perc\",\n",
    "    \"male_with_disability_perc\",\n",
    "    \"female_with_disability_perc\",\n",
    "    \"in_household_perc\",\n",
    "    \"in_household_family_perc\",\n",
    "    \"in_household_non_family_perc\",\n",
    "    \"job_in_the_labor_force_employed_perc\",\n",
    "    \"job_in_the_labor_force_unemployed_perc\",\n",
    "    \"job_not_in_labor_force_perc\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116c25d2",
   "metadata": {},
   "source": [
    "### Bias audit at state level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a01515",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "preds_and_census_data = get_predictions_with_census_data(\n",
    "    db_conn=db_conn,\n",
    "    experiment_id=top_model[\"experiment_id\"][0],\n",
    "    model_id=top_model[\"model_id\"][0],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dec5263",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "for variable in variables_of_interest:\n",
    "    preds_and_census_data[f\"state_{variable}_categorized\"] = pd.cut(\n",
    "        preds_and_census_data[f\"{variable}\"],\n",
    "        bins=preds_and_census_data[f\"{variable}\"]\n",
    "        .quantile([0, 0.25, 0.5, 0.75, 1])\n",
    "        .values,\n",
    "        include_lowest=True,\n",
    "        labels=[\"under_q25\", \"from_q25_to_q50\", \"from_q50_to_q75\", \"over_q75\"],\n",
    "    ).astype(str)\n",
    "variables_of_interest_categorized = [\n",
    "    \"state_\" + variable + \"_categorized\" for variable in variables_of_interest\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4d1f02",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "attributes_and_reference_groups = {\"state\": \"Pennsylvania\"}\n",
    "for variable in variables_of_interest_categorized:\n",
    "    attributes_and_reference_groups[variable] = \"from_q50_to_q75\"\n",
    "attributes_to_audit = list(attributes_and_reference_groups.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba58f20",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>Disclaimer!</b> The metric <i>AUC-ROC</i> is not implemented in the aequitas package. Hence, we compute it manually and we overwrite the metric <i>TPR</i> to take leverage of the ploting functionality of aequitas.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3c4b17",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "df = preds_and_census_data[\n",
    "    [\"y_predicted\", \"y_true\", \"state\"] + variables_of_interest_categorized\n",
    "]\n",
    "df = df.rename(columns={\"y_predicted\": \"score\", \"y_true\": \"label_value\"})\n",
    "\n",
    "metrics_for_audit_bias = [\"tpr\"]\n",
    "disparity_tolerance = 1.30\n",
    "\n",
    "# Initialize Aequitas\n",
    "g = Group()\n",
    "b = Bias()\n",
    "\n",
    "# get_crosstabs returns a dataframe of the group counts and group value bias metrics.\n",
    "xtab, _ = g.get_crosstabs(df, attr_cols=attributes_to_audit)\n",
    "\n",
    "for index, row in xtab.iterrows():\n",
    "    attr_name = row[\"attribute_name\"]\n",
    "    attr_value = row[\"attribute_value\"]\n",
    "\n",
    "    df_attr_value = df[df[attr_name] == attr_value]\n",
    "    xtab.loc[index, \"tpr\"] = metrics.roc_auc_score(\n",
    "        y_true=df_attr_value[\"label_value\"], y_score=df_attr_value[\"score\"]\n",
    "    )\n",
    "\n",
    "bdf = b.get_disparity_predefined_groups(\n",
    "    xtab, original_df=df, ref_groups_dict=attributes_and_reference_groups\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f9e2cc",
   "metadata": {},
   "source": [
    "We do a trick to save png charts since we have some problems with renders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f652cb",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "for variable in attributes_and_reference_groups.keys():\n",
    "    print(f\"audit_bias_at_state_level_variable_{variable}.png\")\n",
    "    chart = ap.disparity(\n",
    "        bdf, metrics_for_audit_bias, variable, fairness_threshold=disparity_tolerance\n",
    "    )\n",
    "    chart.display()\n",
    "    chart.save(\n",
    "        f\"{plots_folder_path_today}audit_bias_at_state_level_variable_{variable}.html\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ff634e",
   "metadata": {},
   "source": [
    "### Bias audit at zcta level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f940fbf0",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "preds_and_census_data_zcta = get_predictions_with_census_data(\n",
    "    db_conn=db_conn,\n",
    "    experiment_id=top_model[\"experiment_id\"][0],\n",
    "    model_id=top_model[\"model_id\"][0],\n",
    "    geography=\"zcta\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fe7b0d",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "variables_of_interest_zcta = variables_of_interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc3cc4b",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "skipped_variables = []\n",
    "for variable in variables_of_interest_zcta:\n",
    "    try:\n",
    "        preds_and_census_data_zcta[f\"zcta_{variable}_categorized\"] = pd.cut(\n",
    "            preds_and_census_data_zcta[f\"{variable}\"],\n",
    "            bins=preds_and_census_data_zcta[f\"{variable}\"]\n",
    "            .quantile([0, 0.25, 0.5, 0.75, 1])\n",
    "            .values,\n",
    "            include_lowest=True,\n",
    "            labels=[\"under_q25\", \"from_q25_to_q50\", \"from_q50_to_q75\", \"over_q75\"],\n",
    "        ).astype(str)\n",
    "    except:\n",
    "        skipped_variables.append(variable)\n",
    "variables_of_interest_categorized = [\n",
    "    \"zcta_\" + variable + \"_categorized\"\n",
    "    for variable in variables_of_interest\n",
    "    if variable not in skipped_variables\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79803408",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"The following variables were skipped due to scarcity of data: {skipped_variables}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0988c72",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "attributes_and_reference_groups = {\n",
    "    \"zcta\": \"94105\"\n",
    "}  # https://codigo-postal.co/en-us/usa/zip/94105/\n",
    "for variable in variables_of_interest_categorized:\n",
    "    attributes_and_reference_groups[variable] = \"from_q50_to_q75\"\n",
    "attributes_to_audit = list(attributes_and_reference_groups.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f51716",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>Disclaimer!</b> The metric <i>AUC-ROC</i> is not implemented in the aequitas package. Hence, we compute it manually and we overwrite the metric <i>TPR</i> to take leverage of the ploting functionality of aequitas.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1f7418",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68021f5e",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "df = preds_and_census_data_zcta[\n",
    "    [\"y_predicted\", \"y_true\", \"zcta\"] + variables_of_interest_categorized\n",
    "]\n",
    "df = df.rename(columns={\"y_predicted\": \"score\", \"y_true\": \"label_value\"})\n",
    "\n",
    "metrics_for_audit_bias = [\"tpr\"]\n",
    "disparity_tolerance = 1.30\n",
    "\n",
    "# Initialize Aequitas\n",
    "g = Group()\n",
    "b = Bias()\n",
    "\n",
    "# get_crosstabs returns a dataframe of the group counts and group value bias metrics.\n",
    "xtab, _ = g.get_crosstabs(df, attr_cols=attributes_to_audit)\n",
    "\n",
    "for index, row in xtab.iterrows():\n",
    "    attr_name = row[\"attribute_name\"]\n",
    "    attr_value = row[\"attribute_value\"]\n",
    "\n",
    "    df_attr_value = df[df[attr_name] == attr_value]\n",
    "    try:\n",
    "        xtab.loc[index, \"tpr\"] = metrics.roc_auc_score(\n",
    "            y_true=df_attr_value[\"label_value\"], y_score=df_attr_value[\"score\"]\n",
    "        )\n",
    "    except:\n",
    "        # If AUC-ROC cannot be computed, we remove the item from the list to avoid meaningless imputation.\n",
    "        print(\n",
    "            f\"The combination of attr_name:{attr_name} and attr_value:{attr_value} has been deleted because auc-roc could not been computed.\"\n",
    "        )\n",
    "        xtab.drop(index)\n",
    "\n",
    "    if math.isnan(xtab.loc[index, \"tpr\"]):\n",
    "        xtab.drop(index)\n",
    "        print(\n",
    "            f\"The combination of attr_name:{attr_name} and attr_value:{attr_value} has been deleted because auc-roc was nan.\"\n",
    "        )\n",
    "\n",
    "bdf = b.get_disparity_predefined_groups(\n",
    "    xtab, original_df=df, ref_groups_dict=attributes_and_reference_groups\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900daffc",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "bdf = bdf.dropna(subset=[\"tpr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e29385",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "bdf.drop(bdf[bdf[\"tpr_disparity\"] == 0].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8298020",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "for variable in attributes_and_reference_groups.keys():\n",
    "    print(f\"audit_bias_model_{best_model_id}_at_zcta_level_variable_{variable}.png\")\n",
    "    chart = ap.disparity(\n",
    "        bdf, metrics_for_audit_bias, variable, fairness_threshold=disparity_tolerance\n",
    "    )\n",
    "    chart.display()\n",
    "    chart.save(\n",
    "        f\"{plots_folder_path_today}audit_bias_model_{best_model_id}_at_zcta_level_variable_{variable}.html\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624970e6",
   "metadata": {},
   "source": [
    "## ROC curves for race variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4beb28e",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "list_of_variables = [\n",
    "    \"race_white_perc\",\n",
    "    \"race_black_or_african_american_perc\",\n",
    "    \"race_american_indian_and_alaska_native_perc\",\n",
    "    \"race_asian_perc\",\n",
    "    #\"race_native_hawaiian_and_other_pacific_islander_perc\",\n",
    "    \"race_hisp_latino_perc\",\n",
    "    \"race_some_other_perc\",\n",
    "    \"race_two_races_or_more_perc\",\n",
    "    \"born_us_perc\",\n",
    "    \"health_insurance_no_perc\",\n",
    "    \"population_size\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f883fb2",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "for variable in list_of_variables:\n",
    "    df = preds_and_census_data_zcta[[\"y_true\", \"y_predicted\", variable]]\n",
    "    df[variable] = pd.cut(\n",
    "        preds_and_census_data_zcta[f\"{variable}\"],\n",
    "        bins=preds_and_census_data_zcta[f\"{variable}\"]\n",
    "        .quantile([0, 0.25, 0.5, 0.75, 1])\n",
    "        .values,\n",
    "        include_lowest=True,\n",
    "        labels=[\"under_q25\", \"from_q25_to_q50\", \"from_q50_to_q75\", \"over_q75\"],\n",
    "    ).astype(str)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "\n",
    "    for index, v in enumerate(df[variable].unique()):\n",
    "        df_v = df[df[variable] == v]\n",
    "        df_v_model_fpr, df_v_model_tpr, thresholds = metrics.roc_curve(\n",
    "            df_v[\"y_true\"], df_v[\"y_predicted\"]\n",
    "        )\n",
    "\n",
    "        sns.lineplot(\n",
    "            x=df_v_model_fpr,\n",
    "            y=df_v_model_tpr,\n",
    "            label=f\"{variable}_{v}\",\n",
    "            color=f\"C{index}\",\n",
    "        )\n",
    "\n",
    "    plt.title(f\"AUC-ROC curve for {variable}\", fontsize=14)\n",
    "    plt.xlabel(\"FPR\", fontsize=14)\n",
    "    plt.ylabel(\"TPR\", fontsize=14)\n",
    "    plt.xlim(0.0, 1.01)\n",
    "    plt.ylim(0.0, 1.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2261685",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "predictions_with_source_data = get_predictions_with_source_data(\n",
    "    db_conn=db_conn, model_id=best_model_id, experiment_id=best_experiment_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea0e0b2",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "variable = \"caller_state_full_name\"\n",
    "df = predictions_with_source_data[[\"y_true\", \"y_predicted\", variable]]\n",
    "\n",
    "auc_per_state = {}\n",
    "for v in df[variable].unique():\n",
    "    try:\n",
    "        df_v = df[df[variable] == v]\n",
    "        auc_per_state[v] = metrics.roc_auc_score(\n",
    "            df_v[\"y_true\"], df_v[\"y_predicted\"]\n",
    "        )\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1bbc1c",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "dict(sorted(auc_per_state.items(), key=lambda x:x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df019670",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "\n",
    "for index, v in enumerate(df[variable].unique()):\n",
    "    try:\n",
    "        df_v = df[df[variable] == v]\n",
    "        df_v_model_fpr, df_v_model_tpr, thresholds = metrics.roc_curve(\n",
    "            df_v[\"y_true\"], df_v[\"y_predicted\"]\n",
    "        )\n",
    "        \n",
    "        if v in [\"Nebraska\", \"District of Columbia\"]:\n",
    "            color = \"red\"\n",
    "            label = True\n",
    "        elif v in [\"Colorado\", \"California\"]:\n",
    "            color = \"orange\"\n",
    "            label = True\n",
    "        elif v in [\"Tennessee\", \"New Mexico\"]:\n",
    "            color = \"green\"\n",
    "            label = True\n",
    "        else:\n",
    "            color = \"gray\"\n",
    "            label = False\n",
    "\n",
    "        if label:\n",
    "            sns.lineplot(\n",
    "                x=df_v_model_fpr,\n",
    "                y=df_v_model_tpr,\n",
    "                label=f\"{v}\",\n",
    "                color=color,\n",
    "            )\n",
    "        else:\n",
    "            sns.lineplot(\n",
    "                x=df_v_model_fpr,\n",
    "                y=df_v_model_tpr,\n",
    "                color=color,\n",
    "            )\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "plt.title(f\"AUC-ROC curve for {variable}\", fontsize=14)\n",
    "plt.xlabel(\"FPR\", fontsize=14)\n",
    "plt.ylabel(\"TPR\", fontsize=14)\n",
    "plt.xlim(0.0, 1.01)\n",
    "plt.ylim(0.0, 1.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1f005c",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "predictions_with_source_data[\"center_key\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192f42fc",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#predictions_with_source_data = get_predictions_with_source_data(\n",
    "#    db_conn=db_conn, model_id=best_model_id, experiment_id=best_experiment_id\n",
    "#)\n",
    "variable = \"center_key\"\n",
    "df = predictions_with_source_data[[\"y_true\", \"y_predicted\", variable]]\n",
    "\n",
    "auc_per_center = {}\n",
    "for v in df[variable].unique():\n",
    "    try:\n",
    "        df_v = df[df[variable] == v]\n",
    "        auc_per_center[v] = metrics.roc_auc_score(\n",
    "            df_v[\"y_true\"], df_v[\"y_predicted\"]\n",
    "        )\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e866da",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "dict(sorted(auc_per_center.items(), key=lambda x:x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f62fe2",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "\n",
    "for index, v in enumerate(df[variable].unique()):\n",
    "    try:\n",
    "        df_v = df[df[variable] == v]\n",
    "        df_v_model_fpr, df_v_model_tpr, thresholds = metrics.roc_curve(\n",
    "            df_v[\"y_true\"], df_v[\"y_predicted\"]\n",
    "        )\n",
    "        \n",
    "        if v in [\"PA724123\", \"GU000671\"]:\n",
    "            color = \"red\"\n",
    "            label = True\n",
    "        elif v in [\"MI660000\", \"IL410000\"]:\n",
    "            color = \"orange\"\n",
    "            label = True\n",
    "        elif v in [\"NY122000\", \"OR503000\"]:\n",
    "            color = \"green\"\n",
    "            label = True\n",
    "        else:\n",
    "            color = \"gray\"\n",
    "            label = False\n",
    "\n",
    "        if label:\n",
    "            sns.lineplot(\n",
    "                x=df_v_model_fpr,\n",
    "                y=df_v_model_tpr,\n",
    "                label=f\"{v}\",\n",
    "                color=color,\n",
    "            )\n",
    "        else:\n",
    "            sns.lineplot(\n",
    "                x=df_v_model_fpr,\n",
    "                y=df_v_model_tpr,\n",
    "                color=color,\n",
    "            )\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "plt.title(f\"AUC-ROC curve for {variable}\", fontsize=14)\n",
    "plt.xlabel(\"FPR\", fontsize=14)\n",
    "plt.ylabel(\"TPR\", fontsize=14)\n",
    "plt.xlim(0.0, 1.01)\n",
    "plt.ylim(0.0, 1.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b76794",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "predictions_with_source_data = get_predictions_with_source_data(\n",
    "    db_conn=db_conn, model_id=best_model_id, experiment_id=best_experiment_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d161144",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "variable = \"arrived_part_of_day\"\n",
    "df = predictions_with_source_data[[\"y_true\", \"y_predicted\", variable]]\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "\n",
    "for index, v in enumerate(df[variable].unique()):\n",
    "    try:\n",
    "        df_v = df[df[variable] == v]\n",
    "        df_v_model_fpr, df_v_model_tpr, thresholds = metrics.roc_curve(\n",
    "            df_v[\"y_true\"], df_v[\"y_predicted\"]\n",
    "        )\n",
    "        \n",
    "        sns.lineplot(\n",
    "            x=df_v_model_fpr,\n",
    "            y=df_v_model_tpr,\n",
    "            label=f\"{v}\",\n",
    "        )\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "plt.title(f\"AUC-ROC curve for {variable}\", fontsize=14)\n",
    "plt.xlabel(\"FPR\", fontsize=14)\n",
    "plt.ylabel(\"TPR\", fontsize=14)\n",
    "plt.xlim(0.0, 1.01)\n",
    "plt.ylim(0.0, 1.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda48f42-2687-4b11-8aee-5d66ca18b909",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889d3fed",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "feature_importance_data = get_feature_importance_from_db(\n",
    "    db_conn=db_conn, model_id=best_model_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3d0c72",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "feature_importance_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3cfcd0",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "top_features = 20\n",
    "\n",
    "f, ax = plt.subplots(figsize=(6, 15))\n",
    "sns.barplot(\n",
    "    x=\"feature_importance\",\n",
    "    y=\"feature_name\",\n",
    "    color=\"b\",\n",
    "    data=feature_importance_data[:top_features],\n",
    ")\n",
    "sns.despine(left=True, bottom=True)\n",
    "\n",
    "f.savefig(\n",
    "    f\"{plots_folder_path_today}feature_importance_top{top_features}_model_{best_model_id}.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88a483a",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "feature_groups_dict = get_feature_groups_dict(modeling_config[\"feature_config\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a35367",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "feature_importance_data_index = feature_importance_data.set_index(\"feature_name\")\n",
    "\n",
    "# The following is a temporal fix tbecause the features table has not been updated with the latest feature names:\n",
    "feature_importance_data_index = feature_importance_data_index.rename(\n",
    "    index={\"arrived_week_of_year_numerics\": \"arrived_datetime_est_week_of_year_numeric\"}\n",
    ")\n",
    "\n",
    "feature_groups_dict_feature_importance = {}\n",
    "for group, variables in feature_groups_dict.items():\n",
    "    if group in [\"datetime\", \"zero_param_alphabet_soup\", \"datetime_imputed\"]:\n",
    "        try:\n",
    "            variables = sum(variables, [])\n",
    "            variables.remove(\"arrived_datetime_local_week_of_year_numeric\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    try:\n",
    "        feature_groups_dict_feature_importance[group] = max(\n",
    "            feature_importance_data_index.loc[variables, \"feature_importance\"]\n",
    "        )\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30020901",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "feature_groups_feature_importance = pd.DataFrame(\n",
    "    list(\n",
    "        zip(\n",
    "            feature_groups_dict_feature_importance.keys(),\n",
    "            feature_groups_dict_feature_importance.values(),\n",
    "        )\n",
    "    ),\n",
    "    columns=[\"feature_group\", \"max_feature_importance\"],\n",
    ")\n",
    "\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.despine(left=True, bottom=True)\n",
    "\n",
    "ax = sns.barplot(\n",
    "    x=\"feature_group\",\n",
    "    y=\"max_feature_importance\",\n",
    "    color=\"b\",\n",
    "    data=feature_groups_feature_importance,\n",
    ")\n",
    "_ = ax.set_xticklabels(ax.get_xticklabels(), rotation=30)\n",
    "\n",
    "f.savefig(\n",
    "    f\"{plots_folder_path_today}feature_group_max_importance_model_{best_model_id}.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e5a530",
   "metadata": {},
   "source": [
    "## Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec5bf1f",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "calibration_data = get_calibration_model(db_conn=db_conn, model_id=best_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dd5d52",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "sns.scatterplot(data=calibration_data, x=\"avg_y_pred\", y=\"avg_y_true\")\n",
    "plt.xlabel(\"Average predicted score\", fontsize=14)\n",
    "plt.ylabel(\"Average true label\", fontsize=14)\n",
    "_ = plt.title(\"Is the model calibrated?\", fontsize=16)\n",
    "\n",
    "f.savefig(f\"{plots_folder_path_today}calibration_results_model_{best_model_id}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f93e96",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "calibration_data = get_calibration_model(\n",
    "    db_conn=db_conn, model_id=best_model_id, round_value=2\n",
    ")\n",
    "\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "sns.scatterplot(data=calibration_data, x=\"avg_y_pred\", y=\"avg_y_true\")\n",
    "plt.xlabel(\"Average predicted score\", fontsize=14)\n",
    "plt.ylabel(\"Average true label\", fontsize=14)\n",
    "_ = plt.title(\"Is the model calibrated?\", fontsize=16)\n",
    "\n",
    "f.savefig(\n",
    "    f\"{plots_folder_path_today}calibration_results_precision2_model_{best_model_id}.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea87433a",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "calibration_data = get_calibration_model(\n",
    "    db_conn=db_conn, model_id=best_model_id, round_value=3\n",
    ")\n",
    "\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "sns.scatterplot(data=calibration_data, x=\"avg_y_pred\", y=\"avg_y_true\")\n",
    "plt.xlabel(\"Average predicted score\", fontsize=14)\n",
    "plt.ylabel(\"Average true label\", fontsize=14)\n",
    "_ = plt.title(\"Is the model calibrated?\", fontsize=16)\n",
    "\n",
    "f.savefig(\n",
    "    f\"{plots_folder_path_today}calibration_results_precision3_model_{best_model_id}.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db8afd1",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "calibration_data = get_calibration_model(\n",
    "    db_conn=db_conn, model_id=best_model_id, round_value=4\n",
    ")\n",
    "\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "sns.scatterplot(data=calibration_data, x=\"avg_y_pred\", y=\"avg_y_true\")\n",
    "plt.xlabel(\"Average predicted score\", fontsize=14)\n",
    "plt.ylabel(\"Average true label\", fontsize=14)\n",
    "_ = plt.title(\"Is the model calibrated?\", fontsize=16)\n",
    "\n",
    "f.savefig(\n",
    "    f\"{plots_folder_path_today}calibration_results_precision4_model_{best_model_id}.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbb938d",
   "metadata": {},
   "source": [
    "## Crosstabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08c2417",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from src.utils.sql_util import (\n",
    "    get_predictions_with_feature_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137cd0dc",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "predictions_with_feature_data = get_predictions_with_feature_data(\n",
    "    db_conn=db_conn, model_id=best_model_id, experiment_id=best_experiment_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b13bef",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "predictions_with_feature_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5db42f8",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "k = 0.5\n",
    "df = predictions_with_feature_data\n",
    "df[\"score\"] = pd.cut(\n",
    "    predictions_with_feature_data[\"y_predicted\"], [0, k, 1], labels=[f\"<{k}\", f\">={k}\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594e2b57",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop(\n",
    "    columns=[\n",
    "        \"routing_attempts_id\",\n",
    "        \"Unnamed: 0\",\n",
    "        \"initiated_datetime_est\",\n",
    "        \"initiated_datetime_est.1\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14af431f",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d17523",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "crosstabs_data = pd.DataFrame(\n",
    "    {\n",
    "        f\"<{k}\": df[df[\"score\"] == f\"<{k}\"].mean(axis=0),\n",
    "        f\">={k}\": df[df[\"score\"] == f\">={k}\"].mean(axis=0),\n",
    "        f\"n_<{k}\": df[df[\"score\"] == f\"<{k}\"].count(),\n",
    "        f\"n_>={k}\": df[df[\"score\"] == f\">={k}\"].count(),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b505c8",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "ratio1 = crosstabs_data[f\"<{k}\"] / crosstabs_data[f\">={k}\"]\n",
    "ratio2 = crosstabs_data[f\">={k}\"] / crosstabs_data[f\"<{k}\"]\n",
    "crosstabs_data[\"max_ratio\"] = np.where(ratio1 > ratio2, ratio1, ratio2)\n",
    "crosstabs_data[\"max_ratio\"] = crosstabs_data[\"max_ratio\"].replace([np.inf, -np.inf], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419e7727",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "crosstabs_data[\"max_ratio\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12802c53",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "crosstabs_data[f\"flag_<{k}_between0and1\"] = crosstabs_data[f\"<{k}\"] < 1\n",
    "crosstabs_data[f\"flag_>={k}_between0and1\"] = crosstabs_data[f\">={k}\"] < 1\n",
    "crosstabs_data[\"flag_between0and1\"] = np.where(\n",
    "    crosstabs_data[f\"flag_>={k}_between0and1\"],\n",
    "    True,\n",
    "    crosstabs_data[f\"flag_<{k}_between0and1\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0272a971",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "crosstabs_data[\"mannwhitneyu_pvalue\"] = -1\n",
    "for attr in crosstabs_data.index:\n",
    "    crosstabs_data.loc[attr, \"mannwhitneyu_pvalue\"] = stats.mannwhitneyu(\n",
    "        df.loc[df[\"score\"] == f\"<{k}\", attr],\n",
    "        df.loc[df[\"score\"] == f\">={k}\", attr],\n",
    "        alternative=\"two-sided\",\n",
    "    )[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779cae05",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "crosstabs_data = crosstabs_data.sort_values(\n",
    "    by=[\"flag_between0and1\", \"max_ratio\"], ascending=[True, False]\n",
    ")\n",
    "pd.set_option(\"display.max_rows\", 650)\n",
    "crosstabs_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97326386",
   "metadata": {},
   "source": [
    "## Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884368bf",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from src.utils.sql_util import get_predictions_with_source_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ef758a",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "predictions_with_source_data = get_predictions_with_source_data(\n",
    "    db_conn=db_conn, model_id=best_model_id, experiment_id=best_experiment_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201ba9c3",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "predictions_with_source_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48fb27a",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "attributes_and_reference_groups = {\n",
    "    \"center_key\": \"PA215000\",\n",
    "    \"arrived_part_of_day\": \"morning\",\n",
    "}\n",
    "attributes_to_audit = list(attributes_and_reference_groups.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03010a6",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>Disclaimer!</b> The metric <i>AUC-ROC</i> is not implemented in the aequitas package. Hence, we compute it manually and we overwrite the metric <i>TPR</i> to take leverage of the ploting functionality of aequitas.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747ce7b8",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361c04b4",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "df = predictions_with_source_data[[\"y_predicted\", \"y_true\"] + attributes_to_audit]\n",
    "df = df.rename(columns={\"y_predicted\": \"score\", \"y_true\": \"label_value\"})\n",
    "\n",
    "metrics_for_audit_bias = [\"tpr\"]\n",
    "disparity_tolerance = 1.30\n",
    "\n",
    "# Initialize Aequitas\n",
    "g = Group()\n",
    "b = Bias()\n",
    "\n",
    "# get_crosstabs returns a dataframe of the group counts and group value bias metrics.\n",
    "xtab, _ = g.get_crosstabs(df, attr_cols=attributes_to_audit)\n",
    "\n",
    "for index, row in xtab.iterrows():\n",
    "    attr_name = row[\"attribute_name\"]\n",
    "    attr_value = row[\"attribute_value\"]\n",
    "\n",
    "    df_attr_value = df[df[attr_name] == attr_value]\n",
    "    try:\n",
    "        xtab.loc[index, \"tpr\"] = metrics.roc_auc_score(\n",
    "            y_true=df_attr_value[\"label_value\"], y_score=df_attr_value[\"score\"]\n",
    "        )\n",
    "    except:\n",
    "        # If AUC-ROC cannot be computed, we remove the item from the list to avoid meaningless imputation.\n",
    "        print(\n",
    "            f\"The combination of attr_name:{attr_name} and attr_value:{attr_value} has been deleted because auc-roc could not been computed.\"\n",
    "        )\n",
    "        xtab.drop(index)\n",
    "\n",
    "    if math.isnan(xtab.loc[index, \"tpr\"]):\n",
    "        xtab.drop(index)\n",
    "        print(\n",
    "            f\"The combination of attr_name:{attr_name} and attr_value:{attr_value} has been deleted because auc-roc was nan.\"\n",
    "        )\n",
    "\n",
    "bdf = b.get_disparity_predefined_groups(\n",
    "    xtab, original_df=df, ref_groups_dict=attributes_and_reference_groups\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5881ddb1",
   "metadata": {},
   "source": [
    "bdf = bdf.dropna(subset=[\"tpr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550146e0",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "bdf.drop(bdf[bdf[\"tpr_disparity\"] == 0].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e500ba",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "for variable in attributes_and_reference_groups.keys():\n",
    "    print(\n",
    "        f\"audit_bias_model_{best_model_id}_absolute_at_cohort_level_variable_{variable}.png\"\n",
    "    )\n",
    "    chart = ap.absolute(\n",
    "        bdf, metrics_for_audit_bias, variable, fairness_threshold=disparity_tolerance\n",
    "    )\n",
    "    chart.display()\n",
    "    chart.save(\n",
    "        f\"{plots_folder_path_today}audit_bias_model_{best_model_id}_absolute_at_cohort_level_variable_{variable}.html\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65fa887",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vibrant-routing",
   "language": "python",
   "name": "vibrant-routing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
